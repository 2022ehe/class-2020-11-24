---
title: "Week 11, Day 3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(PPBDS.data)
library(rstanarm)
library(tidyverse)

# Same data clean up as last week.

set.seed(1005)
week_11 <- shaming %>% 
  mutate(age = 2006 - birth_year) %>% 
  mutate(treatment = fct_relevel(treatment, "Control")) %>% 
  mutate(solo = ifelse(hh_size == 1, TRUE, FALSE)) %>% 
  select(-general_04, -no_of_names, -birth_year, -hh_size) 
```


## Scene 1

**Prompt:** Create a fitted model object called `fit_1` using this formula or, if you want, a formula which you prefer. I recommend not making your model execessively complex.

primary_06 ~ solo + primary_04 + treatment + solo:treatment

(Assume that you have already completed a cross-validation analysis and chosen this one model to use going forward.)

* Which data set should you use to fit the model? Explain why.
```{r sc1, cache = TRUE}
model_1 <- stan_glm(primary_06 ~ solo + primary_04 + treatment + solo*treatment,
                    data = week_11,
                    refresh = 0)

print(model_1, digits = 4)

# Now that we've found the best model, don't want to leave any observations out
```


* Interpret the fitted model. Should we keep all these variables? And the interaction term?

It's nice to keep everything to see how all the factors influence primary turnout.
There are multiple interaction terms, and it's nice to keep all of them to 
look at later.


## Scene 2

**Prompt:** What is the causal effect of receiving the Neighbors postcard as compared to being in the control group? Provide a posterior probability distribution.

* One way to answer this question is to use `posterior_predict()`. Do that. Make it look nice! Write a sentence or two interpreting the answer.

```{r sc2-a}
neighbors <- tibble(solo = TRUE, 
                    primary_04 = "Yes", 
                    treatment = c('Neighbors', 'Control'))

pp <- model_1 %>%
  posterior_predict(newdata = neighbors) %>%
  as_tibble() %>%
  rename('neighbors' = `1`, 'control' = `2`) %>%
  mutate(causal = neighbors - control) %>%
  select(causal)

ggplot(pp, aes(x = causal)) +
  geom_histogram(aes(y = after_stat(count/sum(count))),
                 alpha = 0.7, 
                 bins = 100,
                 color = "white",
                 position = "identity",
                 fill = 'skyblue') + 
  labs(title = "Posterior Predictive Distribution for Causal Effect of Neighbors",
       subtitle = "For a single individual, there is a lot of uncertainty",
       x = "Change in Voting Likelihood",
       y = "Probability") +
  theme_classic()

```


* A second approach uses `posterior_epred()`. Do that. Make it look nice! Write a sentence or two interpreting the answer.

```{r sc2-b}
pp_epred <- model_1 %>%
  posterior_epred(newdata = neighbors) %>%
  as_tibble() %>%
  rename('neighbors' = `1`, 'control' = `2`) %>%
  mutate(causal = neighbors - control) %>%
  select(causal)

ggplot(pp_epred, aes(x = causal)) +
  geom_histogram(aes(y = after_stat(count/sum(count))),
                 alpha = 0.7, 
                 bins = 100,
                 color = "white",
                 position = "identity",
                 fill = 'skyblue') + 
  labs(title = "Posterior Predictive Distribution for Causal Effect of Neighbors",
       subtitle = "For a single individual, there is a lot of uncertainty",
       x = "Change in Voting Likelihood",
       y = "Probability") +
  theme_classic()

```


## Scene 3

**Prompt:** There are four primary causal effects of interest: each of the four treatments compared, individually, to Control.  Build a big graphic which shows the four posterior probability distributions of the expected values at once. See #preceptors-notes for my version. You do not need to copy my work! Make something better!

```{r sc3}
all <- tibble(solo = TRUE, 
                    primary_04 = "Yes", 
                    treatment = c('Neighbors', 'Control', 'Self', 'Hawthorne', 'Civic Duty'))

pp_epred_2 <- model_1 %>%
  posterior_epred(newdata = all) %>%
  as_tibble() %>%
  rename('neighbors' = `1`, 'control' = `2`, 'self' = 3, 'hawthorne' = 4, 'civic' = 5) %>%
  mutate(causal_n = neighbors - control,
         causal_s = self - control,
         causal_h = hawthorne - control,
         causal_c = civic - control) %>%
  select(causal_n, causal_s, causal_h, causal_c) %>%
  pivot_longer(cols = causal_n:causal_c, names_to = 'treatment', values_to = 'effect')

ggplot(pp_epred_2, aes(x = effect, fill = treatment)) +
  geom_histogram(aes(y = after_stat(count/sum(count))),
                 alpha = 0.7, 
                 bins = 100,
                 color = "white",
                 position = "identity") + 
  labs(title = "Posterior Predictive Distribution for Causal Effect of Neighbors",
       subtitle = "For a single individual, there is a lot of uncertainty",
       x = "Change in Voting Likelihood",
       y = "Probability") +
  theme_classic()


```

```{r sc3-alt}
new_obs <- expand_grid(treatment = levels(week_11$treatment),
                       solo = c(TRUE), # challenge questino wuld be (TRUE, FALSE)
                       primary_04 = "Yes")

x <- posterior_epred(model_1, newdata = new_obs) %>%
  as_tibble() %>%
  mutate_all(as.numeric) %>%
  set_names(new_obs$treatment) %>%
  pivot_longer(cols = `Civic Duty`:Neighbors,
               names_to = "treatment",
               values_to = "post")

ggplot(x, aes(x = post, fill = treatment)) +
  geom_histogram(aes(y = after_stat(count/sum(count))),
                 alpha = 0.7, 
                 bins = 100,
                 color = "white",
                 position = "identity") + 
  labs(title = "Posterior Predictive Distribution for Expected Causal Effects",
       subtitle = "Postcards which show neighborhood voting have the biggest effect",
       x = "Change in Voting Likelihood",
       y = "Probability",
       fill = "Treatment") +
  theme_classic() +
  scale_x_continuous(labels = scales::percent_format()) + 
  scale_y_continuous(labels = scales::percent_format()) 
  

```



* Challenge question: Do the same but for both `solo = TRUE` and `solo = FALSE`. This means that there are 8 posterior probability distributions to show. Think hard about the best way to display them. What point are you trying to get across to your readers?



## Optional Question

Use a logistic model --- `stan_glm()` with `family = binomial()` --- to fit the model. How does that change the results above, especially in Scene 2. Chapter 11 provides some relevant discussion?






